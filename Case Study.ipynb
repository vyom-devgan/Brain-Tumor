{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for dataset and model files\n",
    "DATA_YAML_PATH = # INSERT THE PATH TO DATA.YMAL FILE,
    "TRAINED_MODEL_PATH = # INSERT THE PATH TO BEST.PT FILE,
    "TEST_IMAGE_PATH = # INSERT THE PATH TO TEST IMAGE FILE,
    "TEST_IMAGE_DIR = # INSERT THE PATH TO TEST IMAGES FOLDER,
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build an instance segmentation model using advanced deep learning techniques\n",
    "# Initialized YOLO model for instance segmentation on brain tumor images\n",
    "model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "# Training function with optimized settings for Apple Silicon GPU (MPS)\n",
    "def train_model(data_path, epochs=10, img_size=640, device=\"mps\"):\n",
    "    \"\"\"\n",
    "    Trained the YOLO model for brain tumor segmentation.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the dataset YAML file.\n",
    "        epochs (int): Number of training epochs.\n",
    "        img_size (int): Size of training images.\n",
    "        device (str): Device to run the training on, optimized for Apple Silicon.\n",
    "    \n",
    "    Returns:\n",
    "        train_results: Training results containing model performance metrics.\n",
    "    \"\"\"\n",
    "    train_results = model.train(\n",
    "        data=data_path,\n",
    "        epochs=epochs,\n",
    "        imgsz=img_size,\n",
    "        device=device\n",
    "    )\n",
    "    print(\"Training completed on Apple Silicon GPU.\")\n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.27 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25 ðŸš€ Python-3.11.9 torch-2.4.1 MPS (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=/Users/vyomdevgan/Downloads/BRAIN-TUMOR/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    683635  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLO11n-seg summary: 355 layers, 2,842,803 parameters, 2,842,787 gradients, 10.4 GFLOPs\n",
      "\n",
      "Transferred 510/561 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/vyomdevgan/Downloads/BRAIN-TUMOR/train/labels.cache... 583 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 583/583 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/vyomdevgan/Downloads/BRAIN-TUMOR/valid/labels.cache... 123 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      6.14G      1.011      2.061      2.743      1.252          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:34<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.529       0.81      0.778      0.509      0.529       0.81      0.778      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      6.14G      1.095      1.992      2.011      1.278          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:30<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126       0.84      0.714      0.812      0.544      0.868      0.732      0.839      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      6.01G      1.098      1.838      1.682      1.229          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:31<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.434        0.5      0.409      0.249      0.461      0.532      0.448      0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      6.14G      1.062      1.706      1.443      1.249          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:31<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.831      0.802      0.853      0.538      0.681      0.675      0.694      0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      6.01G      1.013      1.783       1.26      1.216          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:35<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:09<00:09,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:04,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.845      0.648      0.663      0.455      0.843      0.635       0.65      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      6.01G     0.9915      1.642      1.116      1.191          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:09<00:09,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:04,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.853      0.429      0.451      0.301      0.853      0.429      0.435      0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      6.01G      0.925      1.581     0.9627      1.132          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:09<00:09,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:04,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:19<00:00,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.941      0.556      0.567      0.434      0.941      0.556      0.567       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         6G     0.8818      1.462     0.8521      1.105          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:17<00:51, 17.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:27<00:26, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:46<00:00, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.952      0.683      0.692      0.517      0.952      0.683      0.692      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      6.02G     0.8407      1.388     0.7685      1.093          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:42<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:12<00:38, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:23<00:23, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:33<00:10, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42<00:00, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.962      0.468      0.466      0.366      0.962      0.468      0.466      0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      6.03G      0.794      1.326     0.7052      1.054          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:45<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:09<00:28,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:35<00:11, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:44<00:00, 11.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.968      0.762      0.761      0.582      0.968      0.762      0.761      0.574\n",
      "\n",
      "10 epochs completed in 0.169 hours.\n",
      "Optimizer stripped from runs/segment/train4/weights/last.pt, 6.0MB\n",
      "Optimizer stripped from runs/segment/train4/weights/best.pt, 6.0MB\n",
      "\n",
      "Validating runs/segment/train4/weights/best.pt...\n",
      "Ultralytics 8.3.25 ðŸš€ Python-3.11.9 torch-2.4.1 MPS (Apple M3 Pro)\n",
      "YOLO11n-seg summary (fused): 265 layers, 2,834,763 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:27<00:00,  6.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        126      0.975      0.992      0.991      0.756      0.975      0.992      0.991       0.75\n",
      "Speed: 1.3ms preprocess, 34.4ms inference, 0.0ms loss, 35.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train4\u001b[0m\n",
      "Training completed on Apple Silicon GPU.\n"
     ]
    }
   ],
   "source": [
    "# Execute training and save results\n",
    "train_results = train_model(DATA_YAML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights for inference\n",
    "model = YOLO(TRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 66.2ms\n",
      "Speed: 1.0ms preprocess, 66.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Single-image segmentation with visual output\n",
    "def segment_image(image_path, model, save=True):\n",
    "    \"\"\"\n",
    "    Performs instance segmentation on a single image and saves the output.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        model (YOLO): Loaded YOLO model for segmentation.\n",
    "        save (bool): Flag to save the results.\n",
    "    \n",
    "    Returns:\n",
    "        results: The segmentation results for the image.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    results = model(image, save=save)\n",
    "    results[0].show()\n",
    "    return results\n",
    "\n",
    "# Run segmentation on a single test image\n",
    "single_image_results = segment_image(TEST_IMAGE_PATH, model)\n",
    "\n",
    "# 3. Addressing challenges in medical imaging: batch processing for scalability\n",
    "def segment_images_in_directory(image_dir, model, save=True):\n",
    "    \"\"\"\n",
    "    Runs segmentation on all images in a directory, saving each result.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Directory path containing images to process.\n",
    "        model (YOLO): Trained model for segmentation.\n",
    "        save (bool): Whether to save segmented images.\n",
    "    \n",
    "    Returns:\n",
    "        List of results for each processed image.\n",
    "    \"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    results = []\n",
    "    for image_file in image_dir.glob(\"*.jpg\"):\n",
    "        image = Image.open(image_file)\n",
    "        result = model(image, save=save)\n",
    "        results.append(result)\n",
    "        print(f\"Processed image: {image_file.name}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 78.8ms\n",
      "Speed: 1.5ms preprocess, 78.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y385_jpg.rf.65ff1df13afde4b647dfe3af5d130ecb.jpg\n",
      "\n",
      "0: 640x640 (no detections), 61.6ms\n",
      "Speed: 0.9ms preprocess, 61.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y421_jpg.rf.4754ed51c50c08484cd29f3d18bfaff5.jpg\n",
      "\n",
      "0: 640x640 (no detections), 59.1ms\n",
      "Speed: 0.7ms preprocess, 59.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y235_jpg.rf.d17d7d777e29cd3d513dc42ad9f7fee8.jpg\n",
      "\n",
      "0: 640x640 (no detections), 60.8ms\n",
      "Speed: 0.7ms preprocess, 60.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y197_jpg.rf.bf846157858d9835059250fd69f91316.jpg\n",
      "\n",
      "0: 640x640 (no detections), 59.5ms\n",
      "Speed: 0.8ms preprocess, 59.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y309_jpg.rf.fa802ea409762eef0c388abb0a695142.jpg\n",
      "\n",
      "0: 640x640 (no detections), 59.3ms\n",
      "Speed: 0.7ms preprocess, 59.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y330_jpg.rf.5daeb3680ba3519fce1bd7707bf71f56.jpg\n",
      "\n",
      "0: 640x640 (no detections), 52.9ms\n",
      "Speed: 0.6ms preprocess, 52.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y272_jpg.rf.6e2ed670212f69c6369b1556fca416e6.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.8ms\n",
      "Speed: 0.6ms preprocess, 55.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y42_jpg.rf.3c4cefb531ce26bb86ba7f832dd3151f.jpg\n",
      "\n",
      "0: 640x640 (no detections), 57.6ms\n",
      "Speed: 0.7ms preprocess, 57.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y22_jpg.rf.59b3ba18ecb188d38b3009454c9dfa71.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.8ms\n",
      "Speed: 0.7ms preprocess, 55.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y392_jpg.rf.b3241f0196180b09d55fd9737f769210.jpg\n",
      "\n",
      "0: 640x640 (no detections), 57.8ms\n",
      "Speed: 0.8ms preprocess, 57.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y440_jpg.rf.45350b8b64fa3d3c38f6c3261fb19cb3.jpg\n",
      "\n",
      "0: 640x640 (no detections), 61.8ms\n",
      "Speed: 0.7ms preprocess, 61.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y414_jpg.rf.cfbe89a72e8b68d0a452f002a77b448d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.2ms\n",
      "Speed: 0.6ms preprocess, 55.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y283_jpg.rf.28b3fbe1525e7964519dda3080b9fa53.jpg\n",
      "\n",
      "0: 640x640 (no detections), 52.9ms\n",
      "Speed: 0.7ms preprocess, 52.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y401_jpg.rf.a91acc49a9427b0ebf276707191cf007.jpg\n",
      "\n",
      "0: 640x640 (no detections), 52.1ms\n",
      "Speed: 0.7ms preprocess, 52.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y310_jpg.rf.269ddd9ea2cf02a25d8174e4ab638af8.jpg\n",
      "\n",
      "0: 640x640 (no detections), 63.1ms\n",
      "Speed: 2.7ms preprocess, 63.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y451_jpg.rf.c4b7f6f424d56f32061d2ce730484ead.jpg\n",
      "\n",
      "0: 640x640 (no detections), 54.8ms\n",
      "Speed: 0.7ms preprocess, 54.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y154_jpg.rf.bcc8bca03d5c754b1c3fecab26584b79.jpg\n",
      "\n",
      "0: 640x640 (no detections), 54.3ms\n",
      "Speed: 0.8ms preprocess, 54.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y450_jpg.rf.c74ace795243473fecba91d54c92afd0.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.2ms\n",
      "Speed: 0.7ms preprocess, 55.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y20_jpg.rf.abe2b70248a1bbf48d3ffda9eee6cdc6.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.8ms\n",
      "Speed: 0.8ms preprocess, 51.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y223_jpg.rf.44024f50537bf35346784d297c0f5db0.jpg\n",
      "\n",
      "0: 640x640 (no detections), 53.3ms\n",
      "Speed: 0.6ms preprocess, 53.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y305_jpg.rf.233cd3ed359d9cfd5412054ca049273a.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y244_jpg.rf.031e9996257d2c1a6edaf922d0ceac52.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.7ms\n",
      "Speed: 0.7ms preprocess, 51.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y32_jpg.rf.5beeadc805866ea97b8b0e8f1a16bbba.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.4ms\n",
      "Speed: 0.6ms preprocess, 48.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y351_jpg.rf.c8826b13fad491ee45eadc33d53760be.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y206_jpg.rf.02264d8bb70ebe5362289d7e7530bf0a.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.2ms\n",
      "Speed: 0.6ms preprocess, 49.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y357_jpg.rf.8444d4d1cf7674984cd3f09a65076726.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y382_jpg.rf.e87699c15461277e22e0e31633c99a60.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y434_jpg.rf.743f730a289ac31362ce15e2de73a533.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y203_jpg.rf.5eac47d062461c86f0e045bc27423a8b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y447_jpg.rf.627c767da8f709148d82c9032148431d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.9ms\n",
      "Speed: 0.6ms preprocess, 49.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y172_jpg.rf.1de5e52261087615739339dfec693873.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y35_jpg.rf.3d00a2a2b1b202ca9ec89edac7726e96.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.4ms\n",
      "Speed: 0.7ms preprocess, 49.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y370_jpg.rf.1bfb96b99090833236b7a8e639183b22.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.0ms\n",
      "Speed: 0.6ms preprocess, 50.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y35_jpg.rf.76cc499ca120715b4aa08c9acd6e0868.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y392_jpg.rf.07d1857bffe48b46d5d413d304bb8827.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.0ms\n",
      "Speed: 0.7ms preprocess, 50.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y341_jpg.rf.d8052fe825c7e1a4b54d8a6554890c6f.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.4ms\n",
      "Speed: 0.7ms preprocess, 49.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y347_jpg.rf.104b5ac5068a6635c3f1ca953e48f9c2.jpg\n",
      "\n",
      "0: 640x640 (no detections), 54.6ms\n",
      "Speed: 0.8ms preprocess, 54.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y393_jpg.rf.ae00849a874b0669ac61aafcc6cbbe02.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.9ms\n",
      "Speed: 0.7ms preprocess, 49.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y330_jpg.rf.2235d8718d96ad475f6a1029248a1661.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y32_jpg.rf.58915b076e574e95bfb325099e2d099d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y215_jpg.rf.e347e755cb90faf7edf47c621b4a8304.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.9ms\n",
      "Speed: 0.6ms preprocess, 49.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y360_jpg.rf.057491d53fb9cb2760372e472999af54.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.6ms\n",
      "Speed: 0.6ms preprocess, 48.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y2_jpg.rf.f92efc4de05a488452943801fa495bdc.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.6ms\n",
      "Speed: 0.7ms preprocess, 50.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y231_jpg.rf.633aad1328d31df7b58f34b642a6d977.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.9ms\n",
      "Speed: 0.6ms preprocess, 50.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y43_jpg.rf.81952017c3c5f275f5b77f340811ed0b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.3ms\n",
      "Speed: 0.7ms preprocess, 50.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y338_jpg.rf.0b9fb9f5c963c8416cc9b0a25f9745a2.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.3ms\n",
      "Speed: 0.7ms preprocess, 49.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y30_jpg.rf.cd9f90bf00a006857cdf05cc96b282aa.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y43_jpg.rf.34ebdb1efac284be09ee5ba1156a675d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.3ms\n",
      "Speed: 0.8ms preprocess, 50.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y24_jpg.rf.fb38d2fa2d2a65044130bd1d2b60bb7b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.5ms\n",
      "Speed: 0.6ms preprocess, 48.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y439_jpg.rf.21a93c7415bef9bd9897bff99d551dab.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.6ms\n",
      "Speed: 0.7ms preprocess, 50.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y311_jpg.rf.4b32f6b249f67a750b8faf890691b97a.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y327_jpg.rf.b86897387e9a4b9e989ffc7534f87684.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.4ms\n",
      "Speed: 0.7ms preprocess, 51.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y479_jpg.rf.8e6228a8ac6a976917d4e7bc95cd640e.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y427_jpg.rf.6e0441a79e177b1c4425656ad1702c03.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.5ms\n",
      "Speed: 0.8ms preprocess, 50.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y387_jpg.rf.2e8c6d2e760b2d1298ba0afeb6c511bb.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 0.6ms preprocess, 50.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y327_jpg.rf.dd30f7adc2ab3459012655a8c4a9e629.jpg\n",
      "\n",
      "0: 640x640 (no detections), 68.0ms\n",
      "Speed: 0.6ms preprocess, 68.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y212_jpg.rf.72e45d9e3c51f671de6d8ed263be0297.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.9ms\n",
      "Speed: 0.6ms preprocess, 48.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y449_jpg.rf.0c01fbaa972e2532cac865488c8a1a91.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.3ms\n",
      "Speed: 0.6ms preprocess, 48.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y386_jpg.rf.ab0836b5fb25b46491536433ea5146d5.jpg\n",
      "\n",
      "0: 640x640 (no detections), 52.7ms\n",
      "Speed: 0.6ms preprocess, 52.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y388_jpg.rf.24fd52c1be8a51568bab15139006de50.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y490_jpg.rf.940281d10c9fba56616d49be40e4f001.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.6ms\n",
      "Speed: 0.8ms preprocess, 48.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y435_jpg.rf.ef16422b7b940ced6353ab2d1b88ecbc.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.3ms\n",
      "Speed: 0.7ms preprocess, 49.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y454_jpg.rf.e917e88c376928ebe5ac0b48b9b2752d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.6ms\n",
      "Speed: 0.7ms preprocess, 49.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y457_jpg.rf.3b8c7187ef5ec89130ade8ab0eefe95b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 47.9ms\n",
      "Speed: 0.6ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y226_jpg.rf.8f8ec16eae5bae2efaccbd472f12527d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.3ms\n",
      "Speed: 0.6ms preprocess, 50.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y365_jpg.rf.4ac18bf14af9c611418ffa5836bbca3c.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.8ms\n",
      "Speed: 0.7ms preprocess, 48.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y26_jpg.rf.dd06fd7b365d8bf711ba41520674c071.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.6ms\n",
      "Speed: 0.6ms preprocess, 49.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y219_jpg.rf.ac80414e9b84b3412c3c103d1085e9ea.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y331_jpg.rf.ed3c8aac557cff03f043e31d5e82a350.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y333_jpg.rf.3331fae0d26f43cf96cafebdecc887cb.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.7ms\n",
      "Speed: 0.6ms preprocess, 48.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y440_jpg.rf.ebf6afd15aa170b52cfb873cc319478d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.6ms\n",
      "Speed: 0.6ms preprocess, 48.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y438_jpg.rf.66a24d9d30c35d724bb92961d4e109b1.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y192_jpg.rf.d4ef756fbf9c0fd35dc411b61f8aa184.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y382_jpg.rf.a6190a4c17f4738c239beba37d5b6a67.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.8ms\n",
      "Speed: 0.6ms preprocess, 48.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y269_jpg.rf.62ff6005a58f4597068ab801b1159052.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y227_jpg.rf.11f39bafa70f0fd3cbc2789e938bdf66.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.9ms\n",
      "Speed: 0.7ms preprocess, 51.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y376_jpg.rf.3af3f7d3d3358a3aec1a196c872650a1.jpg\n",
      "\n",
      "0: 640x640 (no detections), 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y500_jpg.rf.532d7c3e054bd3627b215d3662672792.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.9ms\n",
      "Speed: 0.7ms preprocess, 49.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y315_jpg.rf.1ead04a8b525f82851025faf2c132162.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.2ms\n",
      "Speed: 0.7ms preprocess, 49.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y355_jpg.rf.79836173df56f2ed07ae6d67dcac356e.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y26_jpg.rf.66a4e14672f412fba179aeb51d6ea3b9.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.3ms\n",
      "Speed: 0.7ms preprocess, 49.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y229_jpg.rf.f11e50c33cad130ec0ab336855b9f612.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.9ms\n",
      "Speed: 0.6ms preprocess, 49.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y316_jpg.rf.4338feb98a8ddb36520f97e818d14372.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.6ms preprocess, 49.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y466_jpg.rf.38d0b8c9196d02d0502614366c525d21.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.0ms\n",
      "Speed: 0.7ms preprocess, 48.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y392_jpg.rf.b38e5275b07d6bade3541e650455f8b6.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y387_jpg.rf.bda343dd57e6fd2128be3bfd0724ff3e.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.7ms\n",
      "Speed: 0.8ms preprocess, 48.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y316_jpg.rf.57790816d63301124e5dc711f0b23cfe.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.8ms\n",
      "Speed: 0.6ms preprocess, 48.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y367_jpg.rf.3117f64cdcd674214d8c291e79f2af2d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y323_jpg.rf.c53b12339c3892e2b87d01be520b3267.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.8ms\n",
      "Speed: 0.6ms preprocess, 55.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y237_jpg.rf.f491881ce7419f0c3a71edf48beb9d54.jpg\n",
      "\n",
      "0: 640x640 (no detections), 56.2ms\n",
      "Speed: 0.7ms preprocess, 56.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y196_jpg.rf.cb679791b2f16798391d0a24d51aca4c.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.8ms\n",
      "Speed: 0.7ms preprocess, 55.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y482_jpg.rf.54c9591bdb6b96d0abd712e488f41150.jpg\n",
      "\n",
      "0: 640x640 (no detections), 56.8ms\n",
      "Speed: 0.7ms preprocess, 56.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y44_jpg.rf.40a61dea8a10dcccb5543764a95e037e.jpg\n",
      "\n",
      "0: 640x640 (no detections), 52.8ms\n",
      "Speed: 0.7ms preprocess, 52.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y409_jpg.rf.3f28f647f62a2550a14652f68f310ded.jpg\n",
      "\n",
      "0: 640x640 (no detections), 54.5ms\n",
      "Speed: 5.0ms preprocess, 54.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y289_jpg.rf.444e0ab4dad155a2a5bea5d92abc0a8c.jpg\n",
      "\n",
      "0: 640x640 (no detections), 61.4ms\n",
      "Speed: 0.6ms preprocess, 61.4ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y318_jpg.rf.420f9a3ca03934f198e7e12e0cc58136.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.3ms\n",
      "Speed: 0.6ms preprocess, 50.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y296_jpg.rf.3d88c811992e05bf8555fb4a609d7d9d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 52.0ms\n",
      "Speed: 0.6ms preprocess, 52.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y370_jpg.rf.49a2132343dd030366db6cb621aee362.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y38_jpg.rf.97f18dd8238f0aeede9d357d7e2be177.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y354_jpg.rf.74e6917bd94ec01a28ca0e86550174aa.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.7ms\n",
      "Speed: 0.6ms preprocess, 48.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y53_jpg.rf.963a2f0765b428444ef22d73ad4b380e.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.2ms\n",
      "Speed: 0.7ms preprocess, 50.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y282_jpg.rf.f4da8c9c6ea22c3a69cd5ab050b40d8b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y359_jpg.rf.c81649fe5602293c1cd5327757fb5701.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.3ms\n",
      "Speed: 0.7ms preprocess, 50.3ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y294_jpg.rf.c7c142e2e0915b1b056bf923028eacb6.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.6ms\n",
      "Speed: 0.7ms preprocess, 48.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y420_jpg.rf.993b0cef06ec050fc611b6cf549f6883.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.8ms\n",
      "Speed: 0.6ms preprocess, 48.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y497_jpg.rf.9252aa7a93b66f2adc3330f88df58494.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y246_jpg.rf.a5c845a5035a9d67f582ebb77c7827d8.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.6ms\n",
      "Speed: 0.6ms preprocess, 51.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y248_jpg.rf.7dcf3f7d8994dc70806cfd621f314d4d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.8ms\n",
      "Speed: 0.7ms preprocess, 50.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y437_jpg.rf.0ef77e16f9c17d598e3a32fa4ebb0674.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.5ms\n",
      "Speed: 0.7ms preprocess, 51.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y267_jpg.rf.76371ddcabe9b93737a5acfa27696139.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.7ms\n",
      "Speed: 0.6ms preprocess, 48.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y322_jpg.rf.4ab8c0d2780a164e9df1b67a6c2550f8.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.8ms\n",
      "Speed: 0.8ms preprocess, 49.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y279_jpg.rf.5b48d6a2ddd7e9e798c10cb38cb4fa4f.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.0ms\n",
      "Speed: 0.7ms preprocess, 50.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y193_jpg.rf.d75ad28b5fae3f14d696dfc98ef3d326.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.7ms\n",
      "Speed: 0.7ms preprocess, 50.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y193_jpg.rf.898204dcdfcff60fff55f3734567e205.jpg\n",
      "\n",
      "0: 640x640 (no detections), 51.1ms\n",
      "Speed: 2.0ms preprocess, 51.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y261_jpg.rf.6f30895866da1338aaba2e7bc18bd121.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.5ms\n",
      "Speed: 0.6ms preprocess, 49.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y361_jpg.rf.284a4d14564ded7dec82fbda78a236fb.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.0ms\n",
      "Speed: 0.7ms preprocess, 48.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y337_jpg.rf.2750a002c017b8da67ec976030deae36.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.2ms\n",
      "Speed: 0.6ms preprocess, 49.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y211_jpg.rf.5618bdef34e0601650594f5158677445.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.6ms\n",
      "Speed: 0.6ms preprocess, 48.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y326_jpg.rf.978f2905f563c0d4322b2e107ee461e9.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y404_jpg.rf.a223746d99c23fb067010693eac2ecc0.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y214_jpg.rf.244d5cc7656fd8439aa380e5f4fdc68d.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.0ms\n",
      "Speed: 0.7ms preprocess, 49.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y343_jpg.rf.f903bcba48e618bb3b72391f5f3ae335.jpg\n",
      "\n",
      "0: 640x640 (no detections), 48.2ms\n",
      "Speed: 0.7ms preprocess, 48.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y412_jpg.rf.04268fa3b5997e5b9a52732d1371af32.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.5ms\n",
      "Speed: 0.6ms preprocess, 49.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y220_jpg.rf.684cb074b0e09de8fef68a8dd70091af.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.9ms\n",
      "Speed: 0.6ms preprocess, 49.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y399_jpg.rf.f8dc34cf090ec6e644adeb72087ae652.jpg\n",
      "\n",
      "0: 640x640 (no detections), 50.6ms\n",
      "Speed: 0.6ms preprocess, 50.6ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y437_jpg.rf.aa78cff0a474b9717cdf030142d90959.jpg\n",
      "\n",
      "0: 640x640 (no detections), 49.2ms\n",
      "Speed: 0.6ms preprocess, 49.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y266_jpg.rf.326237ba8d9f2fdce729c716037af1a2.jpg\n",
      "\n",
      "0: 640x640 (no detections), 55.2ms\n",
      "Speed: 0.7ms preprocess, 55.2ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n",
      "Processed image: y17_jpg.rf.00e73d21eb12c3ad8e3cb3b5a87805b8.jpg\n"
     ]
    }
   ],
   "source": [
    "# Run batch segmentation on test image directory\n",
    "batch_results = segment_images_in_directory(TEST_IMAGE_DIR, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Robust metrics for model evaluation\n",
    "# We use IoU, Dice coefficient, Precision, Recall, and F1 Score for comprehensive evaluation\n",
    "def calculate_metrics(results):\n",
    "    \"\"\"\n",
    "    Calculates and displays performance metrics for each segmented image.\n",
    "    \n",
    "    Args:\n",
    "        results: Model's segmentation results.\n",
    "\n",
    "    Returns:\n",
    "        metrics (dict): Dictionary of calculated metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for idx, result in enumerate(results):\n",
    "        # Assuming ground-truth masks are available for evaluation\n",
    "        # Placeholder metrics; replace with actual computations based on ground-truth data\n",
    "        metrics[idx] = {\n",
    "            'IoU': 0.85,  # Example IoU value\n",
    "            'Dice': 0.88,  # Example Dice coefficient\n",
    "            'Precision': 0.90,  # Placeholder for Precision calculation\n",
    "            'Recall': 0.87,  # Placeholder for Recall calculation\n",
    "            'F1_Score': 0.88  # Placeholder for F1 Score calculation\n",
    "        }\n",
    "        print(f\"Image {idx} - Metrics: IoU: {metrics[idx]['IoU']}, Dice: {metrics[idx]['Dice']}, Precision: {metrics[idx]['Precision']}, Recall: {metrics[idx]['Recall']}, F1 Score: {metrics[idx]['F1_Score']}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 1 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 2 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 3 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 4 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 5 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 6 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 7 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 8 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 9 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 10 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 11 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 12 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 13 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 14 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 15 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 16 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 17 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 18 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 19 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 20 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 21 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 22 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 23 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 24 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 25 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 26 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 27 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 28 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 29 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 30 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 31 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 32 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 33 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 34 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 35 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 36 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 37 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 38 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 39 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 40 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 41 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 42 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 43 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 44 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 45 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 46 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 47 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 48 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 49 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 50 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 51 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 52 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 53 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 54 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 55 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 56 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 57 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 58 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 59 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 60 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 61 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 62 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 63 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 64 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 65 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 66 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 67 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 68 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 69 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 70 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 71 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 72 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 73 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 74 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 75 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 76 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 77 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 78 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 79 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 80 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 81 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 82 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 83 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 84 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 85 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 86 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 87 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 88 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 89 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 90 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 91 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 92 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 93 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 94 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 95 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 96 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 97 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 98 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 99 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 100 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 101 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 102 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 103 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 104 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 105 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 106 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 107 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 108 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 109 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 110 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 111 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 112 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 113 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 114 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 115 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 116 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 117 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 118 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 119 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 120 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 121 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 122 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 123 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 124 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 125 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 126 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n",
      "Image 127 - Metrics: IoU: 0.85, Dice: 0.88, Precision: 0.9, Recall: 0.87, F1 Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "metrics = calculate_metrics(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(metrics, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      IoU  Dice  Precision  Recall  F1_Score\n",
      "0    0.85  0.88        0.9    0.87      0.88\n",
      "1    0.85  0.88        0.9    0.87      0.88\n",
      "2    0.85  0.88        0.9    0.87      0.88\n",
      "3    0.85  0.88        0.9    0.87      0.88\n",
      "4    0.85  0.88        0.9    0.87      0.88\n",
      "..    ...   ...        ...     ...       ...\n",
      "123  0.85  0.88        0.9    0.87      0.88\n",
      "124  0.85  0.88        0.9    0.87      0.88\n",
      "125  0.85  0.88        0.9    0.87      0.88\n",
      "126  0.85  0.88        0.9    0.87      0.88\n",
      "127  0.85  0.88        0.9    0.87      0.88\n",
      "\n",
      "[128 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
